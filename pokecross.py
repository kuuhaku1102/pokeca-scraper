from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import base64
import os
import gspread
from google.oauth2.service_account import Credentials

# --- Google Sheets èªè¨¼ ---
with open("credentials.json", "w") as f:
    f.write(base64.b64decode(os.environ["GSHEET_JSON"]).decode("utf-8"))

scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
creds = Credentials.from_service_account_file("credentials.json", scopes=scopes)
gc = gspread.authorize(creds)
spreadsheet = gc.open_by_url("https://docs.google.com/spreadsheets/d/11agq4oxQxT1g9ZNw_Ad9g7nc7PvytHr1uH5BSpwomiE/edit")
sheet = spreadsheet.worksheet("ãã®ä»–")

# --- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆç”»åƒURLã§é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰ ---
existing_data = sheet.get_all_values()[1:]  # 1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ä»®å®š
existing_image_urls = {row[1] for row in existing_data if len(row) > 1}

results = []

with sync_playwright() as p:
    browser = p.chromium.launch(
        headless=True,
        args=['--no-sandbox', '--disable-setuid-sandbox']
    )
    context = browser.new_context(
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    )
    page = context.new_page()
    print("ğŸ” pokeca ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...")

    page_num = 1
    while True:
        try:
            url = f"https://pokeca.com/?page={page_num}"
            page.goto(url, timeout=60000, wait_until="domcontentloaded")
            page.wait_for_selector("div.original-packs-card", timeout=60000)
        except Exception as e:
            print(f"ğŸ›‘ ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            page.screenshot(path=f"error_screenshot_page{page_num}.png")
            html = page.content()
            with open(f"error_page_{page_num}.html", "w", encoding="utf-8") as f:
                f.write(html)
            break

        # ãƒ‡ãƒãƒƒã‚°ç”¨HTMLä¿å­˜
        html = page.content()
        with open(f"page_debug_{page_num}.html", "w", encoding="utf-8") as f:
            f.write(html)

        soup = BeautifulSoup(html, "html.parser")
        cards = soup.select("div.original-packs-card")
        
        # SOLDOUTã®ç¢ºèª
        if soup.select_one("div.soldout"):
            print("ğŸ SOLDOUTãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
            
        if not cards:  # ã‚«ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯çµ‚äº†
            print(f"ğŸ ãƒšãƒ¼ã‚¸ {page_num} ã§ã‚«ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break

        for card in cards:
            a_tag = card.select_one("a.link-underline")
            img_tag = card.select_one("img.card-img-top")
            pt_tag = card.select_one("p.point-amount")

            if not (a_tag and img_tag and pt_tag):
                continue

            title = img_tag.get("alt", "ç„¡é¡Œ").strip()
            image_url = img_tag["src"]
            detail_url = a_tag["href"]
            pt_text = pt_tag.get_text(strip=True).replace("/1å›", "").strip()

            if image_url.startswith("/"):
                image_url = "https://pokeca.com" + image_url
            if detail_url.startswith("/"):
                detail_url = "https://pokeca.com" + detail_url

            if image_url in existing_image_urls:
                print(f"â­ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {title}")
                continue

            print(f"âœ… å–å¾—: {title} / {pt_text}")
            results.append([title, image_url, detail_url, pt_text])

        print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page_num} å®Œäº†")
        page_num += 1

    browser.close()

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ ---
if results:
    next_row = len(existing_data) + 2
    range_string = f"A{next_row}:D{next_row + len(results) - 1}"
    try:
        sheet.update(range_string, results)
        print(f"ğŸ“¦ {len(results)} ä»¶è¿½è¨˜å®Œäº†")
    except Exception as e:
        print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿å¤±æ•—: {str(e)}")
else:
    print("ğŸ“­ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãªã—")
