import os
import re
import time
import json
from urllib.parse import urljoin
from typing import List
import requests
from bs4 import BeautifulSoup

# -----------------------------
# WordPress REST API è¨­å®š
# -----------------------------
WP_URL = os.getenv("WP_URL") or "https://online-gacha-hack.com/wp-json/oripa/v1/upsert"
WP_USER = os.getenv("WP_USER")
WP_APP_PASS = os.getenv("WP_APP_PASS")
WP_GET_URL = "https://online-gacha-hack.com/wp-json/oripa/v1/list"

# -----------------------------
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡è¨­å®š
# -----------------------------
BASE_URL = "https://iris-toreca.com/"
PACK_SELECTOR = "a.pack-content"
THUMBNAIL_SELECTOR = "div.pack-thumbnail img"
PRICE_SELECTOR = "div.pack-price-count i"
TITLE_SELECTOR = "h1"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# -----------------------------
# WordPressæ—¢å­˜URLå–å¾—
# -----------------------------
def fetch_existing_urls() -> set:
    print("ğŸ” WordPressæ—¢å­˜URLã‚’å–å¾—ä¸­...")
    try:
        res = requests.get(WP_GET_URL, auth=(WP_USER, WP_APP_PASS), timeout=30)
        if res.status_code != 200:
            print(f"âš ï¸ URLå–å¾—å¤±æ•—: {res.status_code}")
            return set()
        urls = set(res.json())
        print(f"âœ… æ—¢å­˜URLæ•°: {len(urls)} ä»¶")
        return urls
    except Exception as e:
        print(f"ğŸ›‘ æ—¢å­˜URLå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return set()

# -----------------------------
# HTMLå–å¾—ãƒ˜ãƒ«ãƒ‘ãƒ¼
# -----------------------------
def fetch_page(url: str) -> BeautifulSoup:
    resp = requests.get(url, headers=HEADERS, timeout=30)
    resp.raise_for_status()
    return BeautifulSoup(resp.text, "html.parser")

# -----------------------------
# ä¾¡æ ¼æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
# -----------------------------
def extract_pt(text: str) -> str:
    match = re.search(r"(\d+(?:,\d+)*)", text)
    return match.group(1) if match else ""

# -----------------------------
# ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆè©³ç´°ãƒšãƒ¼ã‚¸ï¼‰
# -----------------------------
def fetch_title(detail_url: str) -> str:
    time.sleep(1)  # polite delay
    try:
        soup = fetch_page(detail_url)
    except Exception as exc:
        print(f"âš  è©³ç´°ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¤±æ•—: {detail_url} ({exc})")
        return ""
    title_tag = soup.select_one(TITLE_SELECTOR)
    if title_tag:
        return title_tag.get_text(strip=True)
    if soup.title:
        return soup.title.get_text(strip=True)
    return ""

# -----------------------------
# ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†
# -----------------------------
def scrape(existing_urls: set) -> List[dict]:
    print("ğŸ” iris-toreca.com ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...")
    soup = fetch_page(BASE_URL)
    results = []

    for a in soup.select(PACK_SELECTOR):
        img_tag = a.select_one(THUMBNAIL_SELECTOR)
        pt_tag = a.select_one(PRICE_SELECTOR)
        image_url = img_tag["src"] if img_tag and img_tag.has_attr("src") else ""
        detail_url = a.get("href", "")
        pt_text = pt_tag.get_text(strip=True) if pt_tag else ""

        if image_url.startswith("/"):
            image_url = urljoin(BASE_URL, image_url)
        if detail_url.startswith("/"):
            detail_url = urljoin(BASE_URL, detail_url)

        if not detail_url or detail_url in existing_urls:
            continue

        pt_value = extract_pt(pt_text)
        title = fetch_title(detail_url) or "noname"

        results.append({
            "source_slug": "iris-toreca",
            "title": title,
            "image_url": image_url,
            "detail_url": detail_url,
            "points": pt_value,
            "price": None,
            "rarity": None,
            "extra": {"scraped_at": time.strftime("%Y-%m-%d %H:%M:%S")}
        })
    print(f"âœ… {len(results)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—å®Œäº†")
    return results

# -----------------------------
# WordPress REST APIæŠ•ç¨¿ï¼ˆé‡è¤‡é™¤å¤–ï¼‰
# -----------------------------
def post_to_wordpress(items: List[dict], existing_urls: set):
    if not items:
        print("ğŸ“­ æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãªã—")
        return

    new_items = [item for item in items if item["detail_url"] not in existing_urls]
    if not new_items:
        print("ğŸ“­ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆå…¨ä»¶æ—¢å­˜ï¼‰")
        return

    print(f"ğŸš€ æ–°è¦ {len(new_items)}ä»¶ã‚’WordPressã«é€ä¿¡ä¸­...")
    try:
        res = requests.post(WP_URL, json=new_items, auth=(WP_USER, WP_APP_PASS), timeout=60)
        print("Status:", res.status_code)
        try:
            print("Response:", json.dumps(res.json(), ensure_ascii=False, indent=2))
        except Exception:
            print("Response:", res.text)
    except Exception as e:
        print(f"ğŸ›‘ WordPressé€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

# -----------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# -----------------------------
def main():
    start = time.time()
    existing_urls = fetch_existing_urls()
    items = scrape(existing_urls)
    post_to_wordpress(items, existing_urls)
    print(f"ğŸ å®Œäº†ï¼å‡¦ç†æ™‚é–“: {round(time.time() - start, 2)} ç§’")

if __name__ == "__main__":
    main()
