from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import base64
import os
import gspread
from google.oauth2.service_account import Credentials

# --- Google Sheets èªè¨¼ ---
with open("credentials.json", "w") as f:
    f.write(base64.b64decode(os.environ["GSHEET_JSON"]).decode("utf-8"))

scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
creds = Credentials.from_service_account_file("credentials.json", scopes=scopes)
gc = gspread.authorize(creds)
spreadsheet = gc.open_by_url("https://docs.google.com/spreadsheets/d/11agq4oxQxT1g9ZNw_Ad9g7nc7PvytHr1uH5BSpwomiE/edit")
sheet = spreadsheet.worksheet("ãã®ä»–")

# --- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆç”»åƒURLã§é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰ ---
existing_data = sheet.get_all_values()[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
existing_image_urls = {row[1] for row in existing_data if len(row) > 1}

results = []

with sync_playwright() as p:
    browser = p.chromium.launch(headless=True, args=['--no-sandbox'])
    page = browser.new_page()
    print("ğŸ” orikuji ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...")
    page.goto("https://orikuji.com/", timeout=60000, wait_until="networkidle")
    
    # ãƒšãƒ¼ã‚¸ãŒå®Œå…¨ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å¾…æ©Ÿ
    page.wait_for_selector("div.theme_newarrival", timeout=30000)

    html = page.content()
    soup = BeautifulSoup(html, "html.parser")
    cards = soup.select("div.theme_newarrival")

    if not cards:
        print("ğŸ›‘ ã‚¬ãƒãƒ£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        print(f"HTML content: {html[:500]}...")  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«HTMLå†…å®¹ã‚’å‡ºåŠ›
    else:
        print(f"Found {len(cards)} cards")  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«è¦‹ã¤ã‹ã£ãŸã‚«ãƒ¼ãƒ‰æ•°ã‚’å‡ºåŠ›
        for card in cards:
            a_tag = card.select_one("a")
            title_img = card.select_one("img.el-image__inner")
            price_tag = card.select_one("span.coin-area")

            if not all([a_tag, title_img, price_tag]):
                print("Missing required elements:", {
                    "a_tag": bool(a_tag),
                    "title_img": bool(title_img),
                    "price_tag": bool(price_tag)
                })  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¸è¶³è¦ç´ ã‚’å‡ºåŠ›
                continue

            title = title_img.get("alt", "ç„¡é¡Œ").strip()
            image_url = title_img.get("src")
            detail_url = a_tag["href"]
            point = price_tag.get_text(strip=True)

            if image_url.startswith("/"):
                image_url = "https://orikuji.com" + image_url
            if detail_url.startswith("/"):
                detail_url = "https://orikuji.com" + detail_url

            print(f"Processing: {title} / {image_url}")  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å‡¦ç†ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›

            if image_url in existing_image_urls:
                print(f"â­ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {title}")
                continue

            print(f"âœ… å–å¾—: {title} / {point}pt")
            results.append([title, image_url, detail_url, point])

    browser.close()

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ ---
if results:
    next_row = len(existing_data) + 2
    range_string = f"A{next_row}:D{next_row + len(results) - 1}"
    try:
        sheet.update(range_string, results)
        print(f"ğŸ“¦ {len(results)} ä»¶è¿½è¨˜å®Œäº†")
    except Exception as e:
        print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ›¸ãè¾¼ã¿å¤±æ•—: {str(e)}")
else:
    print("ğŸ“­ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãªã—")
    print(f"Existing URLs count: {len(existing_image_urls)}")  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«æ—¢å­˜URLæ•°ã‚’å‡ºåŠ›
