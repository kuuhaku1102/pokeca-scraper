import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import base64
import os
import time
import gspread
from google.oauth2.service_account import Credentials

# --- Google Sheets èªè¨¼ ---
with open("credentials.json", "w") as f:
    f.write(base64.b64decode(os.environ["GSHEET_JSON"]).decode("utf-8"))

scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
creds = Credentials.from_service_account_file("credentials.json", scopes=scopes)
gc = gspread.authorize(creds)
spreadsheet = gc.open_by_url("https://docs.google.com/spreadsheets/d/11agq4oxQxT1g9ZNw_Ad9g7nc7PvytHr1uH5BSpwomiE/edit")
sheet = spreadsheet.worksheet("dopa")

# --- æ—¢å­˜ã®ç”»åƒURLãƒªã‚¹ãƒˆå–å¾—ï¼ˆé‡è¤‡ã‚¹ã‚­ãƒƒãƒ—ç”¨ï¼‰ ---
existing_data = sheet.get_all_values()[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼é™¤å¤–
existing_image_urls = {row[1] for row in existing_data if len(row) > 1}

# --- Chrome èµ·å‹•è¨­å®šï¼ˆversion_main=135 â† GitHub Actions ã®Chromeã¨åˆã‚ã›ã‚‹ï¼‰ ---
options = uc.ChromeOptions()
options.add_argument("--headless=new")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--window-size=1280,2000")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

driver = uc.Chrome(options=options, version_main=135)

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹ ---
print("ğŸ” dopa ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹...")
driver.get("https://dopa-game.jp/")

try:
    # HTMLèª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…æ©Ÿ
    WebDriverWait(driver, 10).until(
        lambda d: d.execute_script("return document.readyState") == "complete"
    )

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾…æ©Ÿï¼ˆNext.jså¯¾å¿œï¼‰
    time.sleep(5)

    # ã‚¬ãƒãƒ£ç”»åƒãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿï¼ˆæœ€å¤§15ç§’ï¼‰
    WebDriverWait(driver, 15).until(
        lambda d: len(d.find_elements(By.CSS_SELECTOR, 'a[href*="itemDetail"] img')) >= 1
    )

except Exception:
    print("ğŸ›‘ Cloudflareã¾ãŸã¯JSæç”»ã®é…å»¶ã«ã‚ˆã‚Šèª­ã¿è¾¼ã¿å¤±æ•—")
    print(driver.page_source[:500])
    driver.quit()
    exit()

# --- HTMLå–å¾— & ãƒ‘ãƒ¼ã‚¹ ---
soup = BeautifulSoup(driver.page_source, "html.parser")
cards = soup.select('a[href*="itemDetail"]')

results = []
for card in cards:
    img_tag = card.find("img")
    if not img_tag:
        continue

    title = img_tag.get("alt", "ç„¡é¡Œ").strip()
    image_url = img_tag.get("src")
    detail_url = card["href"]

    if image_url.startswith("/"):
        image_url = "https://dopa-game.jp" + image_url
    if detail_url.startswith("/"):
        detail_url = "https://dopa-game.jp" + detail_url

    if image_url in existing_image_urls:
        print(f"â­ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {title}")
        continue

    print(f"âœ… å–å¾—: {title}")
    results.append([title, image_url, detail_url])

driver.quit()
print(f"ğŸ“¦ æ–°è¦å–å¾—ä»¶æ•°: {len(results)} ä»¶")

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ ---
if results:
    next_row = len(existing_data) + 2
    sheet.update(f"A{next_row}", results)
