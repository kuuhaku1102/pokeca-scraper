import os
import time
import json
import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# --------------------------------
# WordPress REST API è¨­å®š
# --------------------------------
WP_URL = os.getenv("WP_URL", "https://online-gacha-hack.com/wp-json/pokeca/v1/upsert")
WP_LIST_URL = "https://online-gacha-hack.com/wp-json/pokeca/v1/list"
WP_USER = os.getenv("WP_USER")
WP_APP_PASS = os.getenv("WP_APP_PASS")

# --------------------------------
# Seleniumï¼ˆä¸€è¦§ãƒšãƒ¼ã‚¸ã ã‘ä½¿ç”¨ï¼‰
# --------------------------------
options = Options()
options.add_argument("--headless")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--window-size=1280,2000")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)


# --------------------------------
# æ—¢å­˜ URLä¸€è¦§å–å¾—ï¼ˆé‡è¤‡é™¤å¤–ç”¨ï¼‰
# --------------------------------
def fetch_existing_urls():
    try:
        res = requests.get(WP_LIST_URL, auth=(WP_USER, WP_APP_PASS), timeout=20)
        if res.status_code != 200:
            print("âš ï¸ æ—¢å­˜URLå–å¾—å¤±æ•—:", res.status_code)
            return set()
        urls = set(res.json())
        print(f"ğŸ” æ—¢å­˜ {len(urls)} ä»¶")
        return urls
    except Exception as e:
        print("ğŸ›‘ URLå–å¾—ã‚¨ãƒ©ãƒ¼:", e)
        return set()


# --------------------------------
# ä¸€è¦§ãƒšãƒ¼ã‚¸ 1ãƒšãƒ¼ã‚¸åˆ†ã®URLã‚’åé›†ï¼ˆè¤‡æ•°ã‚»ãƒ¬ã‚¯ã‚¿å¯¾å¿œç‰ˆï¼‰
# --------------------------------
def scrape_list_page(page_num):
    url = f"https://pokeca-chart.com/all-card?mode={page_num}"

    try:
        driver.get(url)
        time.sleep(1.2)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1.0)

        soup = BeautifulSoup(driver.page_source, "html.parser")

        urls = set()

        # â‘  ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç³»ã‚«ãƒ¼ãƒ‰
        for a in soup.select("div.cp_card.hover_big a[href]"):
            href = a["href"].strip()
            if href.startswith("/"):
                href = "https://pokeca-chart.com" + href
            if href.startswith("https://pokeca-chart.com/"):
                urls.add(href)

        # â‘¡ cp_card04ï¼ˆæ—§å¼ã®ä¸€è¦§æ§‹é€ ï¼‰
        for a in soup.select("div.cp_card04 a[href]"):
            href = a["href"].strip()
            if href.startswith("/"):
                href = "https://pokeca-chart.com" + href
            if href.startswith("https://pokeca-chart.com/"):
                urls.add(href)

        # â‘¢ JSONãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ç³»ï¼ˆæœ€æ–°ã®ãƒ‡ã‚¶ã‚¤ãƒ³ï¼‰
        for a in soup.select("a.card_link[href]"):
            href = a["href"].strip()
            if href.startswith("/"):
                href = "https://pokeca-chart.com" + href
            if href.startswith("https://pokeca-chart.com/"):
                urls.add(href)

        print(f"ğŸ“„ Page {page_num}: {len(urls)} ä»¶")
        return urls

    except Exception as e:
        print(f"ğŸ›‘ Page {page_num} ã‚¨ãƒ©ãƒ¼:", e)
        return set()


# --------------------------------
# å…¨20ãƒšãƒ¼ã‚¸ã‚’ä¸¦åˆ—ã‚¯ãƒ­ãƒ¼ãƒ«
# --------------------------------
def get_all_card_urls(max_pages=20):
    print("ğŸ” pokeca-chart.com å…¨20ãƒšãƒ¼ã‚¸ã‚¯ãƒ­ãƒ¼ãƒ«â€¦")

    urls = set()

    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = [executor.submit(scrape_list_page, i) for i in range(1, max_pages + 1)]
        for f in as_completed(futures):
            for u in f.result():
                urls.add(u)

    print(f"\nğŸ‰ æœ€çµ‚å–å¾—ã‚«ãƒ¼ãƒ‰URLç·æ•°: {len(urls)} ä»¶\n")
    return list(urls)


# --------------------------------
# è©³ç´°ãƒšãƒ¼ã‚¸å–å¾—ï¼ˆé«˜é€Ÿ requestsï¼‰
# --------------------------------
def fetch_card_detail(url):

    try:
        r = requests.get(url, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")

        # â‘  ã‚«ãƒ¼ãƒ‰å
        name_tag = soup.find("h1")
        card_name = name_tag.text.strip() if name_tag else "noname"

        # â‘¡ ç”»åƒURL
        img_url = ""
        img = soup.find("img")
        if img and img.get("src"):
            img_url = img["src"]
            if not img_url.startswith("http"):
                img_url = "https://pokeca-chart.com" + img_url

        # â‘¢ ä¾¡æ ¼
        prices = {"ç¾å“": "", "ã‚­ã‚ºã‚ã‚Š": "", "PSA10": ""}

        table = soup.find("tbody", id="item-price-table")
        if table:
            rows = table.find_all("tr")
            if len(rows) >= 2:
                cols = rows[1].find_all("td")
                if len(cols) >= 4:
                    prices["ç¾å“"] = cols[1].text.strip()
                    prices["ã‚­ã‚ºã‚ã‚Š"] = cols[2].text.strip()
                    prices["PSA10"] = cols[3].text.strip()

        return {
            "card_name": card_name,
            "image_url": img_url,
            "detail_url": url,
            "price_json": prices,
        }

    except Exception as e:
        print("âš ï¸ Detailã‚¨ãƒ©ãƒ¼:", url, e)
        return None


# --------------------------------
# è©³ç´°ãƒšãƒ¼ã‚¸ã‚’ä¸¦åˆ—å–å¾—
# --------------------------------
def fetch_details_parallel(urls, existing):

    results = []

    def task(u):
        if u in existing:
            print("â­ é‡è¤‡:", u)
            return None
        return fetch_card_detail(u)

    with ThreadPoolExecutor(max_workers=12) as executor:
        futures = [executor.submit(task, u) for u in urls]
        for f in as_completed(futures):
            data = f.result()
            if data:
                results.append(data)

    print(f"\nğŸ“¦ æ–°è¦ã‚«ãƒ¼ãƒ‰ç·æ•°: {len(results)} ä»¶\n")
    return results


# --------------------------------
# 100ä»¶å˜ä½ã§ WordPress ã«é€ä¿¡
# --------------------------------
def send_to_wordpress_batched(items, batch_size=100):

    total = len(items)
    if total == 0:
        print("ğŸ“­ é€ä¿¡å¯¾è±¡ãªã—")
        return

    print(f"ğŸš€ WPã¸ {total} ä»¶é€ä¿¡é–‹å§‹â€¦")

    for i in range(0, total, batch_size):
        batch = items[i:i + batch_size]
        print(f" â†’ Batch {i // batch_size + 1}: {len(batch)} ä»¶")

        try:
            res = requests.post(
                WP_URL,
                json=batch,
                auth=(WP_USER, WP_APP_PASS),
                timeout=40
            )
            print("Status:", res.status_code)
            try:
                print(json.dumps(res.json(), ensure_ascii=False, indent=2))
            except:
                print(res.text)

        except Exception as e:
            print("ğŸ›‘ ãƒãƒƒãƒé€ä¿¡ã‚¨ãƒ©ãƒ¼:", e)


# --------------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# --------------------------------
def main():

    start = time.time()

    existing_urls = fetch_existing_urls()

    # Step1: å…¨20ãƒšãƒ¼ã‚¸ã®URLã‚’ä¸¦åˆ—å–å¾—
    list_urls = get_all_card_urls(max_pages=20)

    # Step2: è©³ç´°ãƒšãƒ¼ã‚¸ã‚’ä¸¦åˆ—å–å¾—
    new_items = fetch_details_parallel(list_urls, existing_urls)

    # Step3: WordPress ã¸ãƒãƒƒãƒé€ä¿¡
    send_to_wordpress_batched(new_items)

    print(f"\nğŸ å®Œäº†ï¼ï¼ˆ{round(time.time() - start, 2)} ç§’ï¼‰")


if __name__ == "__main__":
    main()
